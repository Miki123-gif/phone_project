{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模块导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_name):\n",
    "    '''\n",
    "    传入的是文件路径\n",
    "    读取并对数据进行处理\n",
    "    '''\n",
    "    file_extension = path.splitext(file_name)[1]\n",
    "    if file_extension == '.csv':\n",
    "        data = pd.read_csv(file_name, encoding='gbk')\n",
    "    elif file_extension == '.xlsx':\n",
    "        data = pd.read_excel(file_name, encoding='gbk')\n",
    "    drop_col = ['imei_', 'area_', 'msisdn_']\n",
    "    data.drop(drop_col, axis=1, inplace=True)\n",
    "    col = data.columns\n",
    "    for each in col:\n",
    "        if data[each].dtype == object:\n",
    "            data[each] = data[each].str.replace('\\t', '')\n",
    "    print('data processed successfully')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time(data):\n",
    "    '''\n",
    "    将时间列，转变成index处理。\n",
    "    '''\n",
    "    data.index = pd.to_datetime(data['update_time_'])\n",
    "    print('successfully')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace(data, treshold = 1):\n",
    "    '''\n",
    "    用户的轨迹追踪。\n",
    "    treshhold = 0 设置的阈值。大于这个阈值的才进行轨迹追踪\n",
    "    '''\n",
    "    data['Frequency'] = data.imsi_.map(data.imsi_.value_counts())\n",
    "    return data[data.Frequency >= treshold].groupby(['imsi_', 'update_time_',])['device_id_'].value_counts().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据转化部分\n",
    "\n",
    "def data_transform(data):\n",
    "    data_storage = {}\n",
    "    group_data = data.reset_index(level=1)\n",
    "    misi = list(set(group_data.index))\n",
    "    for each in misi:\n",
    "        data_storage[each] = {}\n",
    "        try:\n",
    "            # 缺失部分的数据都是有问题的，比如1分31秒，传感器统计了两次。\n",
    "            temp = group_data.loc[each, :].to_dict('list')\n",
    "            data_storage[each].update(temp)\n",
    "        except TypeError:\n",
    "            temp = pd.DataFrame(group_data.loc[each,:]).to_dict('list')\n",
    "#             print(f'{each} is missing..')\n",
    "            continue\n",
    "    print('data transform successfully')\n",
    "    return data_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(data):\n",
    "    with open('trace_data.txt', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print('save successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 读取数据\n",
    "    data1 = get_data('../Project Data/20190524-001.csv')\n",
    "\n",
    "    # 获取轨迹数据\n",
    "    data_trace = trace(data1, treshold=1)\n",
    "    \n",
    "    # DF数据转化成表格，然后存储为pickle类型的二进制数据\n",
    "    transform = data_transform(data_trace)\n",
    "    print(len(transform.keys()))\n",
    "    save_to_pickle(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 函数调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processed successfully\n",
      "92509\n",
      "save successfully\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码调试部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据存储 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processed successfully\n"
     ]
    }
   ],
   "source": [
    "data1 = get_data('../Project Data/20190524-001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trace = trace(data1, treshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460110417649620 is missing..\n",
      "460069007035670 is missing..\n",
      "460015766518368 is missing..\n",
      "460016661002199 is missing..\n"
     ]
    }
   ],
   "source": [
    "data_stor = data_transform(data_trace) # 可以发现这些数据缺失了\n",
    "# 检查下这些数据为什么会缺失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trace_data.txt', 'wb') as f:\n",
    "    pickle.dump(data_stor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'update_time_': ['2019-05-23 12:37:07',\n",
       "  '2019-05-23 12:46:31',\n",
       "  '2019-05-23 13:39:46'],\n",
       " 'DX-SZSC001': [0, 0, 0],\n",
       " 'LT-SZSC001': [0, 0, 0],\n",
       " 'YD-SZSC001': [1, 1, 1]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stor[460079768010752]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>update_time_</th>\n",
       "      <th>DX-SZSC001</th>\n",
       "      <th>LT-SZSC001</th>\n",
       "      <th>YD-SZSC001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-23 12:37:07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-23 12:46:31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-23 13:39:46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          update_time_  DX-SZSC001  LT-SZSC001  YD-SZSC001\n",
       "0  2019-05-23 12:37:07           0           0           1\n",
       "1  2019-05-23 12:46:31           0           0           1\n",
       "2  2019-05-23 13:39:46           0           0           1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data_stor[460079768010752])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group_data = data_trace.reset_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    print(x)\n",
    "    temp = {x.updata_time_:(x.DX-SZSC001, x.LT-SZSC001, x.YD-SZSC001)}\n",
    "    d[x].update(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>device_id_</th>\n",
       "      <th>update_time_</th>\n",
       "      <th>DX-SZSC001</th>\n",
       "      <th>LT-SZSC001</th>\n",
       "      <th>YD-SZSC001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imsi_</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-08 21:30:45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-09 08:54:47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-09 21:27:52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-10 08:48:07</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-10 19:28:31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-11 13:45:16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-11 18:25:41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-13 08:53:11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-13 17:00:19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-13 18:46:10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-13 21:24:40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-14 08:46:25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-14 17:56:50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-14 19:12:45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-15 09:49:26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-16 08:51:30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-16 12:21:06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-16 15:22:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-16 18:54:58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-16 21:25:17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-17 08:50:03</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-17 11:54:06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-17 15:11:58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-17 19:07:56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-20 08:51:44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-21 08:54:02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-21 17:57:29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-22 08:56:22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-22 21:24:46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-23 08:54:49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-23 21:27:28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-24 08:55:35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-24 19:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222992312514644</th>\n",
       "      <td>2019-05-24 19:17:10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "device_id_              update_time_  DX-SZSC001  LT-SZSC001  YD-SZSC001\n",
       "imsi_                                                                   \n",
       "222992312514644  2019-05-08 21:30:45           0           1           0\n",
       "222992312514644  2019-05-09 08:54:47           0           1           0\n",
       "222992312514644  2019-05-09 21:27:52           0           1           0\n",
       "222992312514644  2019-05-10 08:48:07           0           1           0\n",
       "222992312514644  2019-05-10 19:28:31           0           1           0\n",
       "222992312514644  2019-05-11 13:45:16           0           1           0\n",
       "222992312514644  2019-05-11 18:25:41           0           1           0\n",
       "222992312514644  2019-05-13 08:53:11           0           1           0\n",
       "222992312514644  2019-05-13 17:00:19           0           1           0\n",
       "222992312514644  2019-05-13 18:46:10           0           1           0\n",
       "222992312514644  2019-05-13 21:24:40           0           1           0\n",
       "222992312514644  2019-05-14 08:46:25           0           1           0\n",
       "222992312514644  2019-05-14 17:56:50           0           1           0\n",
       "222992312514644  2019-05-14 19:12:45           0           1           0\n",
       "222992312514644  2019-05-15 09:49:26           0           1           0\n",
       "222992312514644  2019-05-16 08:51:30           0           1           0\n",
       "222992312514644  2019-05-16 12:21:06           0           1           0\n",
       "222992312514644  2019-05-16 15:22:00           0           1           0\n",
       "222992312514644  2019-05-16 18:54:58           0           1           0\n",
       "222992312514644  2019-05-16 21:25:17           0           1           0\n",
       "222992312514644  2019-05-17 08:50:03           0           1           0\n",
       "222992312514644  2019-05-17 11:54:06           0           1           0\n",
       "222992312514644  2019-05-17 15:11:58           0           1           0\n",
       "222992312514644  2019-05-17 19:07:56           0           1           0\n",
       "222992312514644  2019-05-20 08:51:44           0           1           0\n",
       "222992312514644  2019-05-21 08:54:02           0           1           0\n",
       "222992312514644  2019-05-21 17:57:29           0           1           0\n",
       "222992312514644  2019-05-22 08:56:22           0           1           0\n",
       "222992312514644  2019-05-22 21:24:46           0           1           0\n",
       "222992312514644  2019-05-23 08:54:49           0           1           0\n",
       "222992312514644  2019-05-23 21:27:28           0           1           0\n",
       "222992312514644  2019-05-24 08:55:35           0           1           0\n",
       "222992312514644  2019-05-24 19:14:00           0           1           0\n",
       "222992312514644  2019-05-24 19:17:10           0           1           0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "# d[222992312514644] = {}\n",
    "group_data.loc[222992312514644, :]\n",
    "# d[222992312514644].update(group_data.loc[222992312514644, :].to_dict('list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id_\n",
       "update_time_    2019-05-13 00:55:10\n",
       "DX-SZSC001                        0\n",
       "LT-SZSC001                        2\n",
       "YD-SZSC001                        0\n",
       "Name: 460069007035670, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_data.loc[460069007035670, :] # 与上面的数据进行对比，可以发现这些会报错的id，可能是机器检测错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function to_dict in module pandas.core.frame:\n",
      "\n",
      "to_dict(self, orient='dict', into=<class 'dict'>)\n",
      "    Convert the DataFrame to a dictionary.\n",
      "    \n",
      "    The type of the key-value pairs can be customized with the parameters\n",
      "    (see below).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    orient : str {'dict', 'list', 'series', 'split', 'records', 'index'}\n",
      "        Determines the type of the values of the dictionary.\n",
      "    \n",
      "        - 'dict' (default) : dict like {column -> {index -> value}}\n",
      "        - 'list' : dict like {column -> [values]}\n",
      "        - 'series' : dict like {column -> Series(values)}\n",
      "        - 'split' : dict like\n",
      "          {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
      "        - 'records' : list like\n",
      "          [{column -> value}, ... , {column -> value}]\n",
      "        - 'index' : dict like {index -> {column -> value}}\n",
      "    \n",
      "        Abbreviations are allowed. `s` indicates `series` and `sp`\n",
      "        indicates `split`.\n",
      "    \n",
      "    into : class, default dict\n",
      "        The collections.abc.Mapping subclass used for all Mappings\n",
      "        in the return value.  Can be the actual class or an empty\n",
      "        instance of the mapping type you want.  If you want a\n",
      "        collections.defaultdict, you must pass it initialized.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    dict, list or collections.abc.Mapping\n",
      "        Return a collections.abc.Mapping object representing the DataFrame.\n",
      "        The resulting transformation depends on the `orient` parameter.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.from_dict: Create a DataFrame from a dictionary.\n",
      "    DataFrame.to_json: Convert a DataFrame to JSON format.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'col1': [1, 2],\n",
      "    ...                    'col2': [0.5, 0.75]},\n",
      "    ...                   index=['row1', 'row2'])\n",
      "    >>> df\n",
      "          col1  col2\n",
      "    row1     1  0.50\n",
      "    row2     2  0.75\n",
      "    >>> df.to_dict()\n",
      "    {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\n",
      "    \n",
      "    You can specify the return orientation.\n",
      "    \n",
      "    >>> df.to_dict('series')\n",
      "    {'col1': row1    1\n",
      "             row2    2\n",
      "    Name: col1, dtype: int64,\n",
      "    'col2': row1    0.50\n",
      "            row2    0.75\n",
      "    Name: col2, dtype: float64}\n",
      "    \n",
      "    >>> df.to_dict('split')\n",
      "    {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\n",
      "     'data': [[1, 0.5], [2, 0.75]]}\n",
      "    \n",
      "    >>> df.to_dict('records')\n",
      "    [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\n",
      "    \n",
      "    >>> df.to_dict('index')\n",
      "    {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\n",
      "    \n",
      "    You can also specify the mapping type.\n",
      "    \n",
      "    >>> from collections import OrderedDict, defaultdict\n",
      "    >>> df.to_dict(into=OrderedDict)\n",
      "    OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\n",
      "                 ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\n",
      "    \n",
      "    If you want a `defaultdict`, you need to initialize it:\n",
      "    \n",
      "    >>> dd = defaultdict(list)\n",
      "    >>> df.to_dict('records', into=dd)\n",
      "    [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\n",
      "     defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.to_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 给轨迹追踪增加阈值。记录达到多少次后才追踪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
